from dataloader import CDD_CESMDataset, IUXRayDataset
from torchvision.transforms.v2 import Resize, RandomCrop, CenterCrop, ToImage, ToDtype, Compose
from torch.utils.data import DataLoader
from torch.optim.lr_scheduler import StepLR
from models.featurenet import FeatureNet, FeatureTransformer
from tqdm import tqdm
from itertools import chain
from nltk.tokenize import word_tokenize
from torch.nn.utils.rnn import pad_sequence
import matplotlib.pyplot as plt
import numpy as np
import torch
import argparse
import pickle
import os
import os.path
import matplotlib.pyplot as plt

def parse():
    parser = argparse.ArgumentParser()
    parser.add_argument("--vocabulary-path", type=str, help="the path of the vocabulary file generated by preprocessing/build_vocab.py", default="data/vocab.pkl")
    parser.add_argument("--image-dir", type=str, help="the path of the images directory", default="data/images/images_normalized")
    parser.add_argument("--train-data-csv", type=str, help="the csv file generated by preprocessing/cdd_cesm_preprocessing.py containing training data annotations", default="data/cdd_cesm_train_data.csv")
    parser.add_argument("--val-data-csv", type=str, help="the csv file generated by preprocessing/cdd_cesm_preprocessing.py containing valdation data annotaitons", default="data/cdd_cesm_val_data.csv")
    parser.add_argument("--batch-size", type=int, help="the batch size of the data loader", default=8)
    parser.add_argument("--learning-rate", type=float, help="the learning rate of the model", default=1e-2)
    parser.add_argument("--epochs", type=int, help="the number of epochs to train the model for", default=1)
    parser.add_argument("--optimizer", type=str, help="the optimizer to use to train the model", default="sgd")
    parser.add_argument("--momentum", type=float, help="the momentum of the optimizer", default=0.9)
    parser.add_argument("--weight-decay", type=float, help="the weight decay of the optimizer", default=1e-3)
    parser.add_argument("--gamma", type=float, help="the gamme value of the learning rate scheduler", default=0.1)
    parser.add_argument("--step-size", type=float, help="the step size of the learning rate scheduler", default=30)
    parser.add_argument("--checkpoints", type=str, help="the checkpoints directory to save the model", default="data/checkpoints")
    parser.add_argument("--featurenet-path", type=str, help="the directory to load the model from", default="")
    parser.add_argument("--featuretransformer-path", type=str, help="the directory to load the model from", default="")
    parser.add_argument("--hidden-size", type=int, help="the hidden size of the model (note: this is sensetive to bagnet used for feature extraction)", default=2048)
    parser.add_argument("--dropout", type=float, help="the dropout of the word2vec algorithm", default=0.1)
    parser.add_argument("--nhead", type=int, help="the number of heads used by the multi-head attention in the transformer", default=8)
    parser.add_argument("--num_layers", type=int, help="the number of layers in the transformer", default=2)
    return parser.parse_args()


def train(args, featurenet, dataloader, optimizer, lossfn, vocabulary):
    featurenet.train()
    running_loss = 0.0
    progress_bar = tqdm(enumerate(dataloader), total=len(dataloader))
    for batch, (image, label, _) in progress_bar:
        image = image.to("cuda")
        label = label.to("cuda")

        prediction_class, _ = featurenet(image) 

        optimizer.zero_grad()
        loss = lossfn(prediction_class, label)
        loss.backward()
        optimizer.step()

        running_loss += loss

        progress_bar.set_description(f"Loss: {running_loss / (batch + 1)}")

    return running_loss / len(dataloader)


def validate(args, featurenet, dataloader, lossfn):
    featurenet.eval()
    running_loss = 0.0
    progress_bar = tqdm(enumerate(dataloader), total=len(dataloader))
    with torch.no_grad():
        for batch, (image, label, reports) in progress_bar:
            image = image.to("cuda")
            label = label.to("cuda")

            prediction_class, _ = featurenet(image) 

            loss = lossfn(prediction_class, label)

            running_loss += loss

            progress_bar.set_description(f"Loss: {running_loss / (batch + 1)}")

    return running_loss / len(dataloader)


if __name__ == "__main__":
    args = parse()
    
    vocabulary = None
    with open(args.vocabulary_path, mode="rb") as file:
        vocabulary = pickle.load(file)

    train_dataset = CDD_CESMDataset(image_list_file=args.train_data_csv,
                                  transform=Compose([Resize(234), RandomCrop(224), ToImage(), ToDtype(torch.float32, scale=True)]))
    val_dataset = CDD_CESMDataset(image_list_file=args.val_data_csv,
                                  transform=Compose([Resize(224), CenterCrop(224), ToImage(), ToDtype(torch.float32, scale=True)]), augment=False)
    train_dataloader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)
    val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=True)

    featurenet = FeatureNet(3, args.hidden_size).to("cuda")

    if args.featurenet_path != "":
        featurenet.load_state_dict(torch.load(args.featurenet_path))

    match args.optimizer:
        case "adam":
            optimizer = torch.optim.Adam(featurenet.parameters(), lr=args.learning_rate, weight_decay=args.weight_decay)
        case "sgd":
            optimizer = torch.optim.SGD(featurenet.parameters(), lr=args.learning_rate, momentum=args.momentum, weight_decay=args.weight_decay)
        case _:
            print("Please enter a valid optimizer!\n")
            exit(1)

    scheduler = StepLR(optimizer, args.step_size, args.gamma)
    lossfn = torch.nn.CrossEntropyLoss()

    train_losses = np.zeros(args.epochs, dtype=np.float32)
    validation_losses = np.zeros(args.epochs, dtype=np.float32)
    for epoch in range(args.epochs):
        print(f"Epoch \033[32m{epoch}\033[0m / \033[32m{args.epochs - 1}\033[0m\n")
        train_losses[epoch] = train(args, featurenet, train_dataloader, optimizer, lossfn, vocabulary)
        validation_losses[epoch] = validate(args, featurenet, val_dataloader, lossfn)

        save_path_featurenet = os.path.join(args.checkpoints, f"featurenet_{epoch}.pth")

        torch.save(featurenet.state_dict(), save_path_featurenet)

        scheduler.step()

    fig, ax = plt.subplots()
    ax.plot(np.arange(0, args.epochs), train_losses, label="Training")
    ax.plot(np.arange(0, args.epochs), validation_losses, label="Validation")
    ax.set_xlabel("Epoch")
    ax.set_ylabel("Loss")
    ax.legend()
    plt.savefig("training_curve.png")

