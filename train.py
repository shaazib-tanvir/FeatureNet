from dataloader import IUXRayDataset, num_cls, conditions_table, conditions
from torchvision.transforms.v2 import Resize, CenterCrop, ToImage, ToDtype, Compose
from torch.utils.data import DataLoader
from torch.optim.lr_scheduler import StepLR
from models.featurenet import FeatureNet, AverageFeaturesGRUDecoder, FeatureTransformer
from tqdm import tqdm
from itertools import chain
from nltk.tokenize import word_tokenize
from torch.nn.utils.rnn import pad_sequence
import matplotlib.pyplot as plt
import numpy as np
import torch
import argparse
import pickle
import os.path

def parse():
    parser = argparse.ArgumentParser()
    parser.add_argument("--vocabulary-path", type=str, help="the path of the vocabulary file generated by preprocessing/build_vocab.py", default="data/vocab.pkl")
    parser.add_argument("--image-dir", type=str, help="the path of the images directory", default="data/images/images_normalized")
    parser.add_argument("--train-data-csv", type=str, help="the csv file generated by preprocessing/iu_preprocessing.py containing training data annotations", default="data/iu_train_data.csv")
    parser.add_argument("--val-data-csv", type=str, help="the csv file generated by preprocessing/iu_preprocessing.py containing valdation data annotaitons", default="data/iu_val_data.csv")
    parser.add_argument("--batch-size", type=int, help="the batch size of the data loader", default=4)
    parser.add_argument("--learning-rate", type=float, help="the learning rate of the model", default=1e-2)
    parser.add_argument("--epochs", type=int, help="the number of epochs to train the model for", default=1)
    parser.add_argument("--optimizer", type=str, help="the optimizer to use to train the model", default="sgd")
    parser.add_argument("--momentum", type=float, help="the momentum of the optimizer", default=0.1)
    parser.add_argument("--weight-decay", type=float, help="the weight decay of the optimizer", default=1e-4)
    parser.add_argument("--gamma", type=float, help="the gamme value of the learning rate scheduler", default=0.1)
    parser.add_argument("--step-size", type=float, help="the step size of the learning rate scheduler", default=10)
    parser.add_argument("--checkpoints", type=str, help="the checkpoints directory to savev the model", default="data/checkpoints")
    parser.add_argument("--hidden-size", type=int, help="the hidden size of the model (note: this is sensetive to bagnet used for feature extraction)", default=2048)
    parser.add_argument("--embedding-size", type=int, help="the embedding size of the tokens", default=2048)
    parser.add_argument("--dropout", type=float, help="the dropout of the word2vec algorithm", default=0.1)
    parser.add_argument("--nhead", type=int, help="the number of heads used by the multi-head attention in the transformer", default=8)
    parser.add_argument("--num_layers", type=int, help="the number of layers in the transformer", default=2)
    return parser.parse_args()


def train(args, featurenet, featuretransformer, dataloader, optimizer, lossfn, vocabulary):
    featurenet.train()
    featuretransformer.train()
    running_class_loss = 0.0
    running_report_loss = 0.0
    running_loss = 0.0
    progress_bar = tqdm(enumerate(dataloader), total=len(dataloader))
    for batch, (image, label, reports) in progress_bar:
        image = image.to("cuda")
        label = label.to("cuda")
        reports = [torch.Tensor([vocabulary("<start>")] + [vocabulary(token.lower()) for token in word_tokenize(report)] + [vocabulary("<end>")]).to(torch.int64) for report in reports]
        reports = pad_sequence(reports, batch_first=True)
        reports = reports.to("cuda")

        prediction_class, average_features, features = featurenet(image) 
        prediction_report = featuretransformer(features, reports[:,:-1])

        optimizer.zero_grad()
        loss_class = lossfn(prediction_class, label)
        loss_report = lossfn(prediction_report, reports[:,1:])
        loss = loss_class + loss_report
        loss.backward()
        optimizer.step()

        running_class_loss += loss_class
        running_report_loss += loss_report
        running_loss += loss

        progress_bar.set_description(f"Class Loss: {running_class_loss / (batch + 1)}, Report Loss: {running_report_loss / (batch + 1)}")

    return running_loss / len(dataloader)


def validate(args, featurenet, featuretransformer, dataloader, lossfn):
    featurenet.eval()
    featuretransformer.eval()
    running_class_loss = 0.0
    running_report_loss = 0.0
    running_loss = 0.0
    progress_bar = tqdm(enumerate(dataloader), total=len(dataloader))
    with torch.no_grad():
        for batch, (image, label, reports) in progress_bar:
            image = image.to("cuda")
            label = label.to("cuda")
            reports = [torch.Tensor([vocabulary("<start>")] + [vocabulary(token.lower()) for token in word_tokenize(report)] + [vocabulary("<end>")]).to(torch.int64) for report in reports]
            reports = pad_sequence(reports, batch_first=True)
            reports = reports.to("cuda")

            prediction_class, average_features, features = featurenet(image) 
            prediction_report = featuretransformer(features, reports[:,:-1])

            loss_class = lossfn(prediction_class, label)
            loss_report = lossfn(prediction_report, reports[:,1:])
            loss = loss_class + loss_report

            running_class_loss += loss_class
            running_report_loss += loss_report
            running_loss += loss

            progress_bar.set_description(f"Class Loss: {running_class_loss / (batch + 1)}, Report Loss: {running_report_loss / (batch + 1)}")

    return running_loss / len(dataloader)


if __name__ == "__main__":
    args = parse()
    
    vocabulary = None
    with open(args.vocabulary_path, mode="rb") as file:
        vocabulary = pickle.load(file)

    train_dataset = IUXRayDataset(image_dir=args.image_dir, image_list_file=args.train_data_csv,
                                  transform=Compose([Resize(224), CenterCrop(224), ToImage(), ToDtype(torch.float32, scale=True)]))
    val_dataset = IUXRayDataset(image_dir=args.image_dir, image_list_file=args.val_data_csv,
                                  transform=Compose([Resize(224), CenterCrop(224), ToImage(), ToDtype(torch.float32, scale=True)]))
    train_dataloader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)
    val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=True)

    featurenet = FeatureNet(num_cls).to("cuda")
    featuretransformer = FeatureTransformer(args.hidden_size, args.nhead, args.num_layers, args.dropout, vocabulary).to("cuda")
    match args.optimizer:
        case "adam":
            optimizer = torch.optim.Adam(chain(featurenet.parameters(), featuretransformer.parameters()), lr=args.learning_rate, weight_decay=args.weight_decay)
        case "sgd":
            optimizer = torch.optim.SGD(chain(featurenet.parameters(), featuretransformer.parameters()), lr=args.learning_rate, momentum=args.momentum, weight_decay=args.weight_decay)
        case _:
            print("Please enter a valid optimizer!\n")
            exit(1)

    scheduler = StepLR(optimizer, args.step_size, args.gamma)
    lossfn = torch.nn.CrossEntropyLoss()

    train_losses = np.zeros(args.epochs, dtype=np.float32)
    validation_losses = np.zeros(args.epochs, dtype=np.float32)
    for epoch in range(args.epochs):
        print(f"Epoch \033[32m{epoch}\033[0m / \033[32m{args.epochs - 1}\033[0m\n")
        train_losses[epoch] = train(args, featurenet, featuretransformer, train_dataloader, optimizer, lossfn, vocabulary)
        validation_losses[epoch] = validate(args, featurenet, featuretransformer, val_dataloader, lossfn)

        save_path_featurenet = os.path.join(args.checkpoints, f"featurenet_{epoch}.pth")
        save_path_featuretransformer = os.path.join(args.checkpoints, f"featuretransformer_{epoch}.pth")
        torch.save(featurenet.state_dict(), save_path_featurenet)
        torch.save(featuretransformer.state_dict(), save_path_featuretransformer)

        fig, ax = plt.subplots()
        ax.plot(np.arange(0, args.epochs), train_losses, label="Training")
        ax.plot(np.arange(0, args.epochs), validation_losses, label="Validation")
        ax.set_xlabel("Epoch")
        ax.set_ylabel("Loss")
        ax.legend()
        plt.savefig("training_curve.png")

        scheduler.step()
