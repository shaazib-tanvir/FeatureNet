from dataloader import IUXRayDataset, num_cls, conditions_table, conditions
from torchvision.transforms.v2 import Resize, CenterCrop, ToImage, ToDtype, Compose
from torch.utils.data import DataLoader
from models.featurenet import FeatureNet
from tqdm import tqdm
import matplotlib.pyplot as plt
import numpy as np
import torch
import argparse
import pickle
import os.path


def parse():
    parser = argparse.ArgumentParser()
    parser.add_argument("--vocabulary-path", type=str, help="the path of the vocabulary file generated by preprocessing/build_vocab.py", default="data/vocab.pkl")
    parser.add_argument("--image-dir", type=str, help="the path of the images directory", default="data/images/images_normalized")
    parser.add_argument("--test-data-csv", type=str, help="the csv file generated by preprocessing/iu_preprocessing.py containing testing data annotations", default="data/iu_test_data.csv")
    parser.add_argument("--model-path", type=str, help="the path of the model to test", required=True)
    parser.add_argument("--patch-size", type=int, help="the patch size used by bagnet", default=33)
    return parser.parse_args()


def test(args, model, dataloader):
    correct = 0
    progress_bar = tqdm(enumerate(dataloader), total=len(dataloader))
    with torch.no_grad():
        for batch, (image, label, reports) in progress_bar:
            image = image.to("cuda")
            label = label.to("cuda")

            prediction = model(image)
            if torch.argmax(prediction, dim=1)[0].item() == label[0].item():
                correct += 1

            progress_bar.set_description(f"Accuracy: \033[32m{100 * correct / (batch + 1)}\033[0m%")
    
    print(f"Accuracy: \033[32m{100 * correct / len(dataloader)}\033[0m%")


if __name__ == "__main__":
    args = parse()

    vocabulary = None
    with open(args.vocabulary_path, mode="rb") as file:
        vocabulary = pickle.load(file)

    test_dataset = IUXRayDataset(image_dir=args.image_dir, image_list_file=args.test_data_csv, 
                                 transform=Compose([Resize(224), CenterCrop(224), ToImage(), ToDtype(torch.float32, scale=True)]))
    test_dataloader = DataLoader(test_dataset, shuffle=True)

    model = FeatureNet(num_cls, args.patch_size).to("cuda")
    model.load_state_dict(torch.load(args.model_path))
    model.eval()

    test(args, model, test_dataloader)
